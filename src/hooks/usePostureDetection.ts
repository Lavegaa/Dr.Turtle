import { useEffect, useRef, useState, useCallback } from 'react';
import { PostureDetector } from '../services/mediapipe/PostureDetector';
import { PostureAnalyzer, type TurtleNeckAnalysis, type EarSelection, type PostureThresholds } from '../services/mediapipe/PostureAnalyzer';
import { PERFORMANCE_CONFIG } from '../utils/constants';

interface UsePostureDetectionProps {
  videoElement: HTMLVideoElement | null;
  isActive: boolean;
  onError: (error: string) => void;
  earSelection?: EarSelection;
  thresholds?: PostureThresholds;
}

interface UsePostureDetectionReturn {
  isInitialized: boolean;
  isProcessing: boolean;
  canvasRef: React.RefObject<HTMLCanvasElement | null>;
  landmarkCount: number;
  lastUpdateTime: string;
  turtleNeckAnalysis: TurtleNeckAnalysis | null;
}

export const usePostureDetection = ({
  videoElement,
  isActive,
  onError,
  earSelection = 'auto',
  thresholds = { mildThreshold: -1, severeThreshold: -3 }
}: UsePostureDetectionProps): UsePostureDetectionReturn => {
  const [isInitialized, setIsInitialized] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [landmarkCount, setLandmarkCount] = useState(0);
  const [lastUpdateTime, setLastUpdateTime] = useState('');
  const [turtleNeckAnalysis, setTurtleNeckAnalysis] = useState<TurtleNeckAnalysis | null>(null);
  
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const detectorRef = useRef<PostureDetector | null>(null);
  const analyzerRef = useRef<PostureAnalyzer | null>(null);
  const animationFrameRef = useRef<number>(0);
  const lastProcessTimeRef = useRef<number>(0);

  // MediaPipe ì´ˆê¸°í™”
  useEffect(() => {
    const initializeMediaPipe = async () => {
      try {
        detectorRef.current = new PostureDetector();
        analyzerRef.current = new PostureAnalyzer();
        await detectorRef.current.initialize();
        setIsInitialized(true);
        console.log('ðŸŽ¯ MediaPipeì™€ ê±°ë¶ëª© ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ');
      } catch (error) {
        console.error('MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
        onError('MediaPipe ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    };

    initializeMediaPipe();

    return () => {
      if (detectorRef.current) {
        detectorRef.current.dispose();
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [onError]);

  // ë‹¨ìˆœ ëžœë“œë§ˆí¬ ê°ì§€ ë° ì‹œê°í™” ë£¨í”„
  const processFrame = useCallback(async () => {
    if (!videoElement || !detectorRef.current || !isActive) {
      return;
    }

    const now = performance.now();
    const timeSinceLastProcess = now - lastProcessTimeRef.current;
    const targetInterval = 1000 / PERFORMANCE_CONFIG.TARGET_FPS;

    // FPS ì œí•œ
    if (timeSinceLastProcess < targetInterval) {
      animationFrameRef.current = requestAnimationFrame(processFrame);
      return;
    }

    try {
      setIsProcessing(true);
      lastProcessTimeRef.current = now;

      // í¬ì¦ˆ ê°ì§€
      const poseResult = await detectorRef.current.detectPose(videoElement);
      
      if (poseResult && poseResult.landmarks.length > 0) {
        // ê±°ë¶ëª© ë¶„ì„ìš© í•µì‹¬ ëžœë“œë§ˆí¬ ì²´í¬ (ì–‘ìª½ ê·€, ì–‘ìª½ ì–´ê¹¨)
        const coreIndices = [7, 8, 11, 12];
        const detectedCount = coreIndices.filter(i => 
          (poseResult.landmarks[i]?.visibility ?? 0) > 0.3
        ).length;
        
        setLandmarkCount(detectedCount);
        setLastUpdateTime(new Date().toLocaleTimeString());

        // ê±°ë¶ëª© ë¶„ì„ ìˆ˜í–‰
        let currentAnalysis = null;
        if (analyzerRef.current) {
          currentAnalysis = analyzerRef.current.analyzeTurtleNeck(poseResult.landmarks, earSelection, thresholds);
          setTurtleNeckAnalysis(currentAnalysis);
        }

        // ìº”ë²„ìŠ¤ì— ëžœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
        if (canvasRef.current) {
          detectorRef.current.drawLandmarks(
            canvasRef.current,
            poseResult.landmarks,
            earSelection,
            currentAnalysis?.earPosition || null,
            thresholds
          );
        }
      }
    } catch (error) {
      console.error('í¬ì¦ˆ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      onError('í¬ì¦ˆ ê°ì§€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsProcessing(false);
    }

    // ë‹¤ìŒ í”„ë ˆìž„ ì˜ˆì•½
    animationFrameRef.current = requestAnimationFrame(processFrame);
  }, [videoElement, isActive, onError, earSelection, thresholds]);

  // ê°ì§€ ì‹œìž‘/ì¤‘ì§€
  useEffect(() => {
    if (isActive && isInitialized && videoElement) {
      console.log('ðŸš€ ëžœë“œë§ˆí¬ ê°ì§€ ì‹œìž‘');
      processFrame();
    } else if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isActive, isInitialized, videoElement, processFrame]);

  return {
    isInitialized,
    isProcessing,
    canvasRef,
    landmarkCount,
    lastUpdateTime,
    turtleNeckAnalysis
  };
};